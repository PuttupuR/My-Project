{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0UUxHHDIKUjuG6oNa15Al",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PuttupuR/My-Project/blob/main/Capstone2_Phonepe_Pulse_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfUKjzcaSUJp",
        "outputId": "7c0e6cb9-9118-41c8-b635-47e132cca48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.0)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting blinker>=1.0.0\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.3.4)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.0)\n",
            "Collecting validators>=0.2\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.22.4)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.2)\n",
            "Collecting importlib-metadata>=1.4\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2023.3)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=b5f2f659a97b127767d0e92b0b6f0ed613daccfe969d02a3809d8378c58885cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: watchdog, validators, smmap, pympler, importlib-metadata, blinker, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.31 importlib-metadata-6.6.0 pydeck-0.8.1b0 pympler-1.0.1 smmap-5.0.0 streamlit-1.22.0 validators-0.20.0 watchdog-3.0.0\n"
          ]
        }
      ],
      "source": [
        "#Install the required libraries\n",
        "!pip install streamlit "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone the data from github\n",
        "!git clone https://github.com/PhonePe/pulse.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gP50lpevAYY",
        "outputId": "66566713-631b-4009-8f94-f9b473542d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pulse'...\n",
            "remote: Enumerating objects: 7975, done.\u001b[K\n",
            "remote: Counting objects: 100% (7975/7975), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6637/6637), done.\u001b[K\n",
            "remote: Total 7975 (delta 2465), reused 6527 (delta 1031), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (7975/7975), 2.11 MiB | 4.18 MiB/s, done.\n",
            "Resolving deltas: 100% (2465/2465), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It will show the current dirrectory \n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k3SBmAIvu0n",
        "outputId": "fc7a4bd4-dffa-40f2-b376-94c0167db0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the directory to root\n",
        "%cd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHVw8HKSvcRS",
        "outputId": "984b49d9-e7fc-4be0-f67c-5f7d63fc1a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "%%writefile app.py\n",
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import plotly.express as px\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "#Set the Title of the Page\n",
        "st.title(\"Phonepe_Pulse_data_visulization\")\n",
        "\n",
        "##aggregated_transaction_data- DataSet1\n",
        "\n",
        "# Define the database name and the table name\n",
        "database_name = \"Phonepe_Pulse_data.db\"\n",
        "\n",
        "table_name = \"Agg_transactions\"\n",
        "table_name1 = \"Agg_user\"\n",
        "table_name2 = \"top_transaction\"\n",
        "table_name3 = \"top_user\"\n",
        "table_name4 = \"map_transaction\"\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect(database_name)\n",
        "\n",
        "# Create the transactions table with the desired schema\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Agg_transaction (\n",
        "    state_name TEXT,\n",
        "    years INTEGER,\n",
        "    quarters TEXT,\n",
        "    transaction_type TEXT,\n",
        "    paymentInstruments_count INTEGER,\n",
        "    paymentInstruments_amount REAL\n",
        ");\n",
        "\"\"\"\n",
        "conn.execute(create_table_query)\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "folder_path =  \"/content/pulse/data/aggregated/transaction/country/india/state\"\n",
        "\n",
        "# Get a list of state names in the folder path\n",
        "state_names =  os.listdir(folder_path)\n",
        "\n",
        "# Define empty lists to hold data from the JSON files\n",
        "state_name = []\n",
        "years = []\n",
        "quarters = []\n",
        "transaction_type = []\n",
        "paymentInstruments_count = []\n",
        "paymentInstruments_amount = []\n",
        "\n",
        "\n",
        "# Loop over each state and year in the folder path\n",
        "\n",
        "for state in state_names:\n",
        "  year_path = f\"{folder_path}/{state}\"\n",
        "  year_names =  os.listdir(year_path)\n",
        "  for year in year_names:\n",
        "    quarter_path = f\"{folder_path}/{state}/{year}\"\n",
        "    quarter_names = os.listdir(quarter_path)\n",
        "    for quarter in quarter_names:\n",
        "      data_path = f\"{folder_path}/{state}/{year}/{quarter}\"\n",
        "     \n",
        "      # Load data from JSON file into a DataFrame\n",
        "      df = pd.read_json(data_path) \n",
        "\n",
        "      # Append data to corresponding list\n",
        "      state_name.append(state)  \n",
        "      years.append(int(year))\n",
        "      quarters.append(quarter)\n",
        "      transaction_type.append(df['data'].values[2][1]['name'])\n",
        "      paymentInstruments_count.append(int(df['data'].values[2][1]['paymentInstruments'][0]['count']))\n",
        "      paymentInstruments_amount.append(float(df['data'].values[2][1]['paymentInstruments'][0]['amount']))\n",
        "\n",
        "# Combine lists into a single DataFrame\n",
        "\n",
        "df_agg_tran = pd.concat([pd.DataFrame(state_name, columns=['state_name']),\n",
        "                 pd.DataFrame(years, columns=['years']),\n",
        "                 pd.DataFrame(quarters, columns=['quarters']),\n",
        "                 pd.DataFrame(transaction_type, columns=['transaction_type']),\n",
        "                 pd.DataFrame(paymentInstruments_count, columns=['paymentInstruments_count']),\n",
        "                 pd.DataFrame(paymentInstruments_amount, columns=['paymentInstruments_amount'])], axis=1)\n",
        "\n",
        "\n",
        "# Insert the data into the transactions table\n",
        "df_agg_tran.to_sql(table_name, conn, if_exists='append', index=False)\n",
        "\n",
        "\n",
        "# Create a connection to the database\n",
        "conn1 = sqlite3.connect(database_name)\n",
        "\n",
        "# Create the user table with the desired schema\n",
        "create_table_query1 = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Agg_users (\n",
        "    state_name TEXT,\n",
        "    years INTEGER,\n",
        "    quarters TEXT,\n",
        "    registeredUsers INTEGER,\n",
        "    appOpens REAL\n",
        ");\n",
        "\"\"\"\n",
        "conn1.execute(create_table_query1)\n",
        "\n",
        "folder_path1 =  \"/content/pulse/data/aggregated/user/country/india/state\"\n",
        "state_names1 =  os.listdir(folder_path)\n",
        "\n",
        "state_name1 = []\n",
        "years1 = []\n",
        "quarters1 = []\n",
        "registeredUsers1 = []\n",
        "appOpens1 = []\n",
        "\n",
        "# Loop over each state and year in the folder path\n",
        "\n",
        "for state in state_names1:\n",
        "  year_path = f\"{folder_path1}/{state}\"\n",
        "  year_names =  os.listdir(year_path)\n",
        "  for year in year_names:\n",
        "    quarter_path = f\"{folder_path1}/{state}/{year}\"\n",
        "    quarter_names = os.listdir(quarter_path)\n",
        "    for quarter in quarter_names:\n",
        "      data_path = f\"{folder_path1}/{state}/{year}/{quarter}\"\n",
        "\n",
        "      # Load data from JSON file into a DataFrame\n",
        "      df = pd.read_json(data_path) \n",
        "      \n",
        "      # Append data to corresponding list\n",
        "      state_name1.append(state)  \n",
        "      years1.append(int(year))\n",
        "      quarters1.append(quarter)\n",
        "      registeredUsers1.append(df['data'].values[0]['registeredUsers'])\n",
        "      appOpens1.append(df['data'].values[0]['appOpens'])\n",
        "\n",
        "# Combine lists into a single DataFrame      \n",
        "df_agg_user = pd.concat([pd.DataFrame(state_name1, columns=['state_name']),\n",
        "                 pd.DataFrame(years1, columns=['years']),\n",
        "                 pd.DataFrame(quarters1, columns=['quarters']),\n",
        "                 pd.DataFrame(registeredUsers1, columns=['registeredUsers']),\n",
        "                 pd.DataFrame(appOpens1, columns=['appOpens'])], axis=1)\n",
        "\n",
        "# Insert the data into the transactions table\n",
        "df_agg_user.to_sql(table_name1, conn1, if_exists='append', index=False)\n",
        "\n",
        "# Create a connection to the database\n",
        "conn2 = sqlite3.connect(database_name)\n",
        "\n",
        "# Create the user table with the desired schema\n",
        "create_table_query2 = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS top_transactions (\n",
        "    state_name TEXT,\n",
        "    years INTEGER,\n",
        "    quarters TEXT,\n",
        "    entity_name TEXT,\n",
        "    count REAL\n",
        "    amount REAL\n",
        ");\n",
        "\"\"\"\n",
        "conn2.execute(create_table_query2)\n",
        "\n",
        "folder_path2 =  \"/content/pulse/data/top/transaction/country/india/state\"\n",
        "state_names2 =  os.listdir(folder_path)\n",
        "\n",
        "state_name2 = []\n",
        "years2 = []\n",
        "quarters2 = []\n",
        "entity_name2 = []\n",
        "count2 = []\n",
        "amount2 = []\n",
        "\n",
        "# Loop over each state and year in the folder path\n",
        "\n",
        "for state in state_names2:\n",
        "  for year in year_names:\n",
        "    for quarter in quarter_names:\n",
        "      data_path = f\"/content/pulse/data/top/transaction/country/india/state/{state}/{year}/{quarter}\"\n",
        "      \n",
        "      # Load data from JSON file into a DataFrame\n",
        "      df = pd.read_json(data_path) \n",
        "\n",
        "      # Append data to corresponding list\n",
        "      state_name2.append(state)  \n",
        "      years2.append(year)\n",
        "      quarters2.append(quarter)\n",
        "      entity_name2.append(df['data'].values[0][0]['entityName'])\n",
        "      count2.append(df['data'].values[0][0]['metric']['count'])\n",
        "      amount2.append(df['data'].values[0][0]['metric']['amount'])\n",
        "\n",
        "# Combine lists into a single DataFrame      \n",
        "df_top_tran = pd.concat([pd.DataFrame(state_name2, columns=['state_name']),\n",
        "                 pd.DataFrame(years2, columns=['years']),\n",
        "                 pd.DataFrame(quarters2, columns=['quarters']),\n",
        "                 pd.DataFrame(entity_name2, columns=['entity_name']),\n",
        "                 pd.DataFrame(count2, columns=['count']),\n",
        "                 pd.DataFrame(amount2, columns=['amount'])], axis=1)\n",
        "\n",
        "\n",
        "# Insert the data into the transactions table\n",
        "df_top_tran.to_sql(table_name2, conn2, if_exists='append', index=False)\n",
        "\n",
        "# Create a connection to the database\n",
        "conn3 = sqlite3.connect(database_name)\n",
        "\n",
        "# Create the user table with the desired schema\n",
        "create_table_query3 = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS top_users (\n",
        "    state_name TEXT,\n",
        "    years INTEGER,\n",
        "    quarters TEXT,\n",
        "    district TEXT,\n",
        "    registeredUsers REAL\n",
        "    \n",
        ");\n",
        "\"\"\"\n",
        "conn3.execute(create_table_query3)\n",
        "\n",
        "folder_path3 =  \"/content/pulse/data/top/user/country/india/state\"\n",
        "state_names3 =  os.listdir(folder_path3)\n",
        "\n",
        "state_name3 = []\n",
        "years3 = []\n",
        "quarters3 = []\n",
        "district3 = []\n",
        "registeredUsers3 = []\n",
        "\n",
        "# Loop over each state and year in the folder path\n",
        "\n",
        "for state in state_names3:\n",
        "  for year in year_names:\n",
        "    for quarter in quarter_names:\n",
        "      data_path = f\"/content/pulse/data/top/user/country/india/state/{state}/{year}/{quarter}\"\n",
        "      \n",
        "      # Load data from JSON file into a DataFrame\n",
        "      df = pd.read_json(data_path) \n",
        "\n",
        "      # Append data to corresponding list\n",
        "      state_name3.append(state)  \n",
        "      years3.append(year)\n",
        "      quarters3.append(quarter)\n",
        "      district3.append(df['data'].values[0][0]['name'])\n",
        "      registeredUsers3.append(df['data'].values[0][0]['registeredUsers'])\n",
        "      \n",
        "# Combine lists into a single DataFrame      \n",
        "df_top_user = pd.concat([pd.DataFrame(state_name3, columns=['state_name']),\n",
        "                 pd.DataFrame(years3, columns=['years']),\n",
        "                 pd.DataFrame(quarters3, columns=['quarters']),\n",
        "                 pd.DataFrame(district3, columns=['district']),\n",
        "                 pd.DataFrame(registeredUsers3, columns=['registeredUsers'])], axis=1)\n",
        "\n",
        "# Insert the data into the transactions table\n",
        "df_top_user.to_sql(table_name3, conn3, if_exists='append', index=False)\n",
        "\n",
        "# Create a connection to the database\n",
        "conn4 = sqlite3.connect(database_name)\n",
        "\n",
        "# Create the user table with the desired schema\n",
        "create_table_query4 = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS map_transactions (\n",
        "    state_name TEXT,\n",
        "    years INTEGER,\n",
        "    quarters TEXT,\n",
        "    district TEXT,\n",
        "    count REAL\n",
        "    amount REAL\n",
        ");\n",
        "\"\"\"\n",
        "conn4.execute(create_table_query4)\n",
        "\n",
        "folder_path4 =  \"/content/pulse/data/map/transaction/hover/country/india/state\"\n",
        "state_names4 =  os.listdir(folder_path4)\n",
        "\n",
        "state_name4 = []\n",
        "years4 = []\n",
        "quarters4 = []\n",
        "district4 = []\n",
        "count4 = []\n",
        "amount4 = []\n",
        "\n",
        "# Loop over each state and year in the folder path\n",
        "\n",
        "for state in state_names4:\n",
        "  for year in year_names:\n",
        "    for quarter in quarter_names:\n",
        "      data_path = f\"/content/pulse/data/map/transaction/hover/country/india/state/{state}/{year}/{quarter}\"\n",
        "      \n",
        "      # Load data from JSON file into a DataFrame\n",
        "      df = pd.read_json(data_path) \n",
        "\n",
        "      # Append data to corresponding list\n",
        "      state_name4.append(state)  \n",
        "      years4.append(year)\n",
        "      quarters4.append(quarter)\n",
        "      district4.append(df['data'].values[0][0]['name'])\n",
        "      count4.append(df['data'].values[0][0]['metric'][0]['count'])\n",
        "      amount4.append(df['data'].values[0][0]['metric'][0]['amount'])\n",
        "\n",
        "# Combine lists into a single DataFrame      \n",
        "df_map_tran = pd.concat([pd.DataFrame(state_name4, columns=['state_name']),\n",
        "                 pd.DataFrame(years4, columns=['years']),\n",
        "                 pd.DataFrame(quarters4, columns=['quarters']),\n",
        "                 pd.DataFrame(district4, columns=['district']),\n",
        "                 pd.DataFrame(count4, columns=['count']),\n",
        "                 pd.DataFrame(amount4, columns=['amount'])], axis=1)\n",
        "\n",
        "# Insert the data into the transactions table\n",
        "df_map_tran.to_sql(table_name4, conn4, if_exists='append', index=False)\n",
        "\n",
        "# Load datasets into dataframes\n",
        "df1 = df_agg_tran\n",
        "df1_x_col = \"paymentInstruments_count\"\n",
        "df1_y_col = \"paymentInstruments_amount\"\n",
        "\n",
        "df2 = df_agg_user\n",
        "df2_x_col = \"quarters\"\n",
        "df2_y_col = \"registeredUsers\"\n",
        "\n",
        "df3 = df_top_tran\n",
        "df3_x_col = \"count\"\n",
        "df3_y_col = \"amount\"\n",
        "\n",
        "df4 = df_top_user\n",
        "df4_x_col = \"district\"\n",
        "df4_y_col = \"registeredUsers\"\n",
        "\n",
        "df5 = df_map_tran\n",
        "df5_x_col = \"district\"\n",
        "df5_y_col = \"count\"\n",
        "\n",
        "# Create a Streamlit sidebar to select the dataset\n",
        "data_selection = st.sidebar.selectbox(\"Select dataset\", [\"Dataset 1\", \"Dataset 2\",\"Dataset 3\",\"Dataset 4\",\"Dataset 5\"])\n",
        "\n",
        "# Filter the selected dataset and column names\n",
        "if data_selection == \"Dataset 1\":\n",
        "    df = df1\n",
        "    x_col = df1_x_col\n",
        "    y_col = df1_y_col\n",
        "elif data_selection == \"Dataset 2\":\n",
        "    df = df2\n",
        "    x_col = df2_x_col\n",
        "    y_col = df2_y_col\n",
        "elif data_selection == \"Dataset 3\":\n",
        "    df = df3\n",
        "    x_col = df3_x_col\n",
        "    y_col = df3_y_col \n",
        "elif data_selection == \"Dataset 4\":\n",
        "    df = df4\n",
        "    x_col = df4_x_col\n",
        "    y_col = df4_y_col         \n",
        "else:\n",
        "    df = df5\n",
        "    x_col = df5_x_col\n",
        "    y_col = df5_y_col\n",
        "\n",
        "# Create a Streamlit dropdown menu to select the type of plot or chart to display\n",
        "chart_type = st.sidebar.selectbox('Please choose the option that corresponds to how you would like the data to be displayed.',\n",
        "             ['Line chart','Pie Chart','Bar Chart','Scatter Plot','Box Plot','Violin Plot','Histogram'])\n",
        " \n",
        "st.write('You selected:', chart_type)\n",
        "\n",
        "\n",
        "# Create the chart based on the selected chart type and display it in Streamlit\n",
        "if chart_type == \"Line chart\":\n",
        "    fig = px.line(df, x=x_col, y=y_col,color=\"state_name\")\n",
        "elif chart_type == \"Pie Chart\":\n",
        "    fig = px.pie(df, values=x_col, names=y_col, color=\"state_name\")\n",
        "elif chart_type == \"Bar Chart\":\n",
        "    fig = px.bar(df, x=x_col, y=y_col,color=\"state_name\")\n",
        "elif chart_type == \"Scatter Plot\":\n",
        "    fig = px.scatter(df, x=x_col, y=y_col,color=\"state_name\")  \n",
        "elif chart_type == \"Box Plot\":\n",
        "    fig = px.box(df, x=x_col, y=y_col,color=\"state_name\") \n",
        "elif chart_type == \"Violin Plot\":\n",
        "    fig = px.violin(df, x=x_col, y=y_col,color=\"state_name\") \n",
        "elif chart_type == \"Histogram\":\n",
        "    fig = px.histogram(df, x=x_col, y=y_col,color=\"state_name\")                        \n",
        "st.plotly_chart(fig)\n",
        "\n",
        "# calling the Nominatim tool\n",
        "loc = Nominatim(user_agent=\"GetLoc\",timeout = 100)\n",
        "\n",
        "for i in state_name:\n",
        "  # entering the location name\n",
        "  getLoc = loc.geocode(i)\n",
        "  # printing address\n",
        "  st.write(getLoc.address)\n",
        "  #printing latitude and longitude\n",
        "  st.write(\"Latitude = \", getLoc.latitude, \"\\n\")\n",
        "  st.write(\"Longitude = \", getLoc.longitude)\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "conn1.close()    \n",
        "conn2.close()\n",
        "conn3.close()\n",
        "conn4.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH0xXbi_SZzm",
        "outputId": "10c3e52a-e32a-4536-9a45-96d9329fb9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Streamlit app in the background using the \"run\" command and the name of the file\n",
        "# Use npx localtunnel to create a public URL for the Streamlit app running on port 8501\n",
        "# This will allow others to access the app from the internet\n",
        "\n",
        "!streamlit run app.py & npx localtunnel --port 8501 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDiNlDK3Sh29",
        "outputId": "5a5c08ce-ca8c-44bc-e010-1ed6faecdc50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[############......] - finalize:yargs: sill finalize /root/.npm/_npx/5805/lib/n\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.73s\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.120.99:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://good-days-stand-34-75-120-99.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}